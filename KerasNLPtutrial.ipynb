{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPe6hSyEDubhKLzAEEkKSC6"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sR8Y4ayGD31R",
        "outputId": "66a91c25-e566-4dd7-e202-efcbe5335ccc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 151 kB 5.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 5.8 MB 37.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 588.3 MB 17 kB/s \n",
            "\u001b[K     |████████████████████████████████| 5.9 MB 59.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 578.1 MB 7.2 kB/s \n",
            "\u001b[K     |████████████████████████████████| 578.1 MB 5.7 kB/s \n",
            "\u001b[K     |████████████████████████████████| 4.6 MB 55.2 MB/s \n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q keras-nlp"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import keras_nlp\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "policy = keras.mixed_precision.Policy(\"mixed_float16\")\n",
        "keras.mixed_precision.set_global_policy(policy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jNJ2ZpuDEMLE",
        "outputId": "fefa6c76-a93f-4087-b036-f573b32494af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Mixed precision compatibility check (mixed_float16): WARNING\n",
            "The dtype policy mixed_float16 may run slowly because this machine does not have a GPU. Only Nvidia GPUs with compute capability of at least 7.0 run quickly with mixed_float16.\n",
            "If you will use compatible GPU(s) not attached to this host, e.g. by running a multi-worker model, you can ignore this warning. This message will only be logged once\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.python.ops.math_ops import truediv\n",
        "keras.utils.get_file(\n",
        "    origin=\"https://s3.amazonaws.com/research.metamind.io/wikitext/wikitext-103-raw-v1.zip\",\n",
        "    extract=True,\n",
        ")\n",
        "wiki_dir = os.path.expanduser(\"~/.keras/datasets/wikitext-103-raw/\")\n",
        "\n",
        "keras.utils.get_file(\n",
        "    origin=\"https://dl.fbaipublicfiles.com/glue/data/SST-2.zip\", extract=True,\n",
        ")\n",
        "sst_dir = os.path.expanduser(\"~/.keras/datasets/SST-2/\")\n",
        "\n",
        "vocab_file = keras.utils.get_file(\n",
        "    origin=\"https://storage.googleapis.com/tensorflow/keras-nlp/examples/bert/bert_vocab_uncased.txt\",\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HJK5Epo5EhfZ",
        "outputId": "c043ff38-97ee-4060-f2ea-fd2ed33ff03b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://s3.amazonaws.com/research.metamind.io/wikitext/wikitext-103-raw-v1.zip\n",
            "191984949/191984949 [==============================] - 3s 0us/step\n",
            "Downloading data from https://dl.fbaipublicfiles.com/glue/data/SST-2.zip\n",
            "7439277/7439277 [==============================] - 1s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-nlp/examples/bert/bert_vocab_uncased.txt\n",
            "231508/231508 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocessing params.\n",
        "PRETRAINING_BATCH_SIZE = 128\n",
        "FINETUNING_BATCH_SIZE = 32\n",
        "SEQ_LENGTH = 128\n",
        "MASK_RATE = 0.25\n",
        "PREDICTIONS_PER_SEQ = 32\n",
        "\n",
        "# Model params.\n",
        "NUM_LAYERS = 3\n",
        "MODEL_DIM = 256\n",
        "INTERMEDIATE_DIM = 512\n",
        "NUM_HEADS = 4\n",
        "DROPOUT = 0.1\n",
        "NORM_EPSILON = 1e-5\n",
        "\n",
        "# Training params.\n",
        "PRETRAINING_LEARNING_RATE = 5e-4\n",
        "PRETRAINING_EPOCHS = 8\n",
        "FINETUNING_LEARNING_RATE = 5e-5\n",
        "FINETUNING_EPOCHS = 3"
      ],
      "metadata": {
        "id": "n_QEfF5vGSSc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sst_train_ds = tf.data.experimental.CsvDataset(\n",
        "    sst_dir + \"train.tsv\", [tf.string, tf.int32], header=True, field_delim=\"\\t\"\n",
        ").batch(FINETUNING_BATCH_SIZE)\n",
        "\n",
        "sst_val_ds = tf.data.experimental.CsvDataset(\n",
        "    sst_dir + \"dev.tsv\", [tf.string, tf.int32], header=True, field_delim=\"\\t\"    \n",
        ").batch(FINETUNING_BATCH_SIZE)\n",
        "\n",
        "wiki_train_ds = (\n",
        "    tf.data.TextLineDataset(wiki_dir+\"wiki.train.raw\")\n",
        "    .filter(lambda x: tf.strings.length(x) > 100)\n",
        "    .batch(PRETRAINING_BATCH_SIZE)\n",
        ")\n",
        "\n",
        "wiki_val_ds = (\n",
        "    tf.data.TextLineDataset(wiki_dir+\"wiki.valid.raw\")\n",
        "    .filter(lambda x: tf.strings.length(x) > 100)\n",
        "    .batch(PRETRAINING_BATCH_SIZE)    \n",
        ")\n",
        "\n",
        "print(sst_train_ds.unbatch().batch(4).take(1).get_single_element())\n",
        "#print(sst_val_ds.unbatch().batch(4).take(1).get_single_element())\n",
        "#print(wiki_train_ds.unbatch().batch(4).take(1).get_single_element())\n",
        "#print(wiki_val_ds.unbatch().batch(4).take(1).get_single_element())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TnoXJsFSGWgh",
        "outputId": "eacd7946-89d1-4d77-ae46-6f0385a462d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(<tf.Tensor: shape=(4,), dtype=string, numpy=\n",
            "array([b'hide new secretions from the parental units ',\n",
            "       b'contains no wit , only labored gags ',\n",
            "       b'that loves its characters and communicates something rather beautiful about human nature ',\n",
            "       b'remains utterly satisfied to remain the same throughout '],\n",
            "      dtype=object)>, <tf.Tensor: shape=(4,), dtype=int32, numpy=array([0, 0, 1, 0], dtype=int32)>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "multi_hot_layer = keras.layers.TextVectorization(\n",
        "    max_tokens=4000, output_mode=\"multi_hot\"\n",
        ")\n",
        "multi_hot_layer.adapt(sst_train_ds.map(lambda x, y: x))\n",
        "\n",
        "regression_layer = keras.layers.Dense(1, activation=\"sigmoid\")\n",
        "\n",
        "inputs = keras.Input(shape=(), dtype=\"string\")\n",
        "outputs = regression_layer(multi_hot_layer(inputs))\n",
        "baseline_model = keras.Model(inputs, outputs)\n",
        "baseline_model.compile(loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
        "baseline_model.fit(sst_train_ds, validation_data=sst_val_ds, epochs=5)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rsc8tM6oJJbg",
        "outputId": "557c47f2-1afa-488d-bb06-44835fdf47d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "2105/2105 [==============================] - 14s 6ms/step - loss: 0.6134 - accuracy: 0.6873 - val_loss: 0.5383 - val_accuracy: 0.7477\n",
            "Epoch 2/5\n",
            "2105/2105 [==============================] - 12s 6ms/step - loss: 0.5250 - accuracy: 0.7604 - val_loss: 0.4891 - val_accuracy: 0.7775\n",
            "Epoch 3/5\n",
            "2105/2105 [==============================] - 13s 6ms/step - loss: 0.4783 - accuracy: 0.7880 - val_loss: 0.4680 - val_accuracy: 0.7936\n",
            "Epoch 4/5\n",
            "2105/2105 [==============================] - 11s 5ms/step - loss: 0.4479 - accuracy: 0.8025 - val_loss: 0.4587 - val_accuracy: 0.7959\n",
            "Epoch 5/5\n",
            "2105/2105 [==============================] - 11s 5ms/step - loss: 0.4261 - accuracy: 0.8125 - val_loss: 0.4557 - val_accuracy: 0.7982\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f63c64981c0>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = keras_nlp.tokenizers.WordPieceTokenizer(\n",
        "    vocabulary=vocab_file,\n",
        "    sequence_length=SEQ_LENGTH,\n",
        "    lowercase=True,\n",
        "    strip_accents=True\n",
        ")\n",
        "\n",
        "masker = keras_nlp.layers.MLMMaskGenerator(\n",
        "    vocabulary_size = tokenizer.vocabulary_size(),\n",
        "    mask_selection_rate=MASK_RATE,\n",
        "    mask_selection_length=PREDICTIONS_PER_SEQ,\n",
        "    mask_token_id=tokenizer.token_to_id(\"[MASK]\")\n",
        ")\n",
        "\n",
        "def preprocess(inputs):\n",
        "  inputs = tokenizer(inputs)\n",
        "  outputs = masker(inputs)\n",
        "\n",
        "  features = {\n",
        "      \"tokens\": outputs[\"tokens\"],\n",
        "      \"mask_positions\": outputs[\"mask_positions\"]\n",
        "  }\n",
        "  labels = outputs[\"mask_ids\"]\n",
        "  weights = outputs[\"mask_weights\"]\n",
        "  return features, labels, weights\n",
        "\n",
        "pretrains_ds = wiki_train_ds.map(\n",
        "    preprocess, num_parallel_calls=tf.data.AUTOTUNE\n",
        ").prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "pretrains_val_ds=wiki_val_ds.map(\n",
        "    preprocess, num_parallel_calls=tf.data.AUTOTUNE\n",
        ").prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "print(pretrains_val_ds.take(1).get_single_element())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kudx3mRqx3il",
        "outputId": "53bc6e9e-b578-4b26-e07b-124ca099760d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "({'tokens': <tf.Tensor: shape=(128, 128), dtype=int32, numpy=\n",
            "array([[ 103, 7849, 2271, ..., 9673, 1012, 7570],\n",
            "       [7570, 7849, 2271, ..., 1007,  421, 2023],\n",
            "       [1996,  103, 3940, ...,    0,    0,    0],\n",
            "       ...,\n",
            "       [2076, 1996, 2307, ...,    0,    0,    0],\n",
            "       [3216, 2225, 2083, ...,    0,    0,    0],\n",
            "       [ 103, 2007, 1045, ...,    0,    0,    0]], dtype=int32)>, 'mask_positions': <tf.Tensor: shape=(128, 32), dtype=int64, numpy=\n",
            "array([[  0,   3,   7, ..., 110, 119, 123],\n",
            "       [  3,   5,   8, ..., 117, 121, 126],\n",
            "       [  1,   3,   9, ...,   0,   0,   0],\n",
            "       ...,\n",
            "       [  4,   6,   9, ..., 117, 119,   0],\n",
            "       [  5,   6,  10, ...,   0,   0,   0],\n",
            "       [  0,   9,  10, ...,   0,   0,   0]])>}, <tf.Tensor: shape=(128, 32), dtype=int32, numpy=\n",
            "array([[ 7570, 13091,  2004, ...,  3344,  2077, 24000],\n",
            "       [13091,  2003, 19116, ...,  2170,  1006,  1012],\n",
            "       [ 2034,  1997,  2007, ...,     0,     0,     0],\n",
            "       ...,\n",
            "       [ 1010,  1997, 23133, ...,  1999,  3462,     0],\n",
            "       [ 5900,  1010,  5982, ...,     0,     0,     0],\n",
            "       [ 9794,  2103,  1998, ...,     0,     0,     0]], dtype=int32)>, <tf.Tensor: shape=(128, 32), dtype=float16, numpy=\n",
            "array([[1., 1., 1., ..., 1., 1., 1.],\n",
            "       [1., 1., 1., ..., 1., 1., 1.],\n",
            "       [1., 1., 1., ..., 0., 0., 0.],\n",
            "       ...,\n",
            "       [1., 1., 1., ..., 1., 1., 0.],\n",
            "       [1., 1., 1., ..., 0., 0., 0.],\n",
            "       [1., 1., 1., ..., 0., 0., 0.]], dtype=float16)>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = keras.Input(shape=(SEQ_LENGTH,), dtype=tf.int32)\n",
        "\n",
        "embedding_layer = keras_nlp.layers.TokenAndPositionEmbedding(\n",
        "    vocabulary_size=tokenizer.vocabulary_size(),\n",
        "    sequence_length=SEQ_LENGTH,\n",
        "    embedding_dim=MODEL_DIM\n",
        ")\n",
        "outputs = embedding_layer(inputs)\n",
        "\n",
        "outputs = keras.layers.LayerNormalization(epsilon=NORM_EPSILON)(outputs)\n",
        "outputs = keras.layers.Dropout(rate=DROPOUT)(outputs)\n",
        "\n",
        "for i in range(NUM_LAYERS):\n",
        "  outputs = keras_nlp.layers.TransformerEncoder(\n",
        "      intermediate_dim=INTERMEDIATE_DIM,\n",
        "      num_heads=NUM_HEADS,\n",
        "      dropout=DROPOUT,\n",
        "      layer_norm_epsilon=NORM_EPSILON\n",
        "  )(outputs)\n",
        "\n",
        "  encoder_model = keras.Model(inputs, outputs)\n",
        "  encoder_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kDhZPAtf2_Vp",
        "outputId": "ed13b828-08c4-4907-99cf-4876b7285f1a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(None, 128)]             0         \n",
            "                                                                 \n",
            " token_and_position_embeddin  (None, 128, 256)         7846400   \n",
            " g (TokenAndPositionEmbeddin                                     \n",
            " g)                                                              \n",
            "                                                                 \n",
            " layer_normalization (LayerN  (None, 128, 256)         512       \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 128, 256)          0         \n",
            "                                                                 \n",
            " transformer_encoder (Transf  (None, 128, 256)         527104    \n",
            " ormerEncoder)                                                   \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 8,374,016\n",
            "Trainable params: 8,374,016\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Model: \"model_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(None, 128)]             0         \n",
            "                                                                 \n",
            " token_and_position_embeddin  (None, 128, 256)         7846400   \n",
            " g (TokenAndPositionEmbeddin                                     \n",
            " g)                                                              \n",
            "                                                                 \n",
            " layer_normalization (LayerN  (None, 128, 256)         512       \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 128, 256)          0         \n",
            "                                                                 \n",
            " transformer_encoder (Transf  (None, 128, 256)         527104    \n",
            " ormerEncoder)                                                   \n",
            "                                                                 \n",
            " transformer_encoder_1 (Tran  (None, 128, 256)         527104    \n",
            " sformerEncoder)                                                 \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 8,901,120\n",
            "Trainable params: 8,901,120\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Model: \"model_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(None, 128)]             0         \n",
            "                                                                 \n",
            " token_and_position_embeddin  (None, 128, 256)         7846400   \n",
            " g (TokenAndPositionEmbeddin                                     \n",
            " g)                                                              \n",
            "                                                                 \n",
            " layer_normalization (LayerN  (None, 128, 256)         512       \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 128, 256)          0         \n",
            "                                                                 \n",
            " transformer_encoder (Transf  (None, 128, 256)         527104    \n",
            " ormerEncoder)                                                   \n",
            "                                                                 \n",
            " transformer_encoder_1 (Tran  (None, 128, 256)         527104    \n",
            " sformerEncoder)                                                 \n",
            "                                                                 \n",
            " transformer_encoder_2 (Tran  (None, 128, 256)         527104    \n",
            " sformerEncoder)                                                 \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 9,428,224\n",
            "Trainable params: 9,428,224\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = {\n",
        "    \"tokens\": keras.Input(shape=(SEQ_LENGTH,), dtype=tf.int32),\n",
        "    \"mask_positions\": keras.Input(shape=(PREDICTIONS_PER_SEQ,), dtype=tf.int32)\n",
        "}\n",
        "\n",
        "encoded_tokens = encoder_model(inputs[\"tokens\"])\n",
        "\n",
        "outputs = keras_nlp.layers.MLMHead(\n",
        "    embedding_weights=embedding_layer.token_embedding.embeddings, activation=\"softmax\",\n",
        ")(encoded_tokens, mask_positions=inputs[\"mask_positions\"])\n",
        "\n",
        "pretraining_model = keras.Model(inputs, outputs)\n",
        "pretraining_model.compile(\n",
        "    loss=\"sparse_categorical_crossentropy\",\n",
        "    optimizer=keras.optimizers.Adam(learning_rate=PRETRAINING_LEARNING_RATE),\n",
        "    weighted_metrics=[\"sparse_categorical_accuracy\"],\n",
        "    jit_compile=True\n",
        ")\n",
        "\n",
        "pretraining_model.fit(\n",
        "    pretrains_ds, validation_data=pretrains_val_ds, epochs=PRETRAINING_EPOCHS\n",
        ")\n",
        "\n",
        "encoder_model.save(\"encoder_model\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GtBHfMpu-a1t",
        "outputId": "e86f2eca-b317-484b-957a-8af6bbeebce4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/8\n",
            "      2/Unknown - 2269s 1141s/step - loss: 8.8086 - sparse_categorical_accuracy: 0.0020    "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess(sentences, labels):\n",
        "  return tokenizer(sentences), labels\n",
        "\n",
        "  finetune_ds = sst_train_ds.map(\n",
        "      preprocess, num_parallel_calls=tf.data.AUTOTUNE\n",
        "  ).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "  finetune_val_ds = sst_val_ds.map(\n",
        "      preprocess, num_parallel_calls=tf.data.AUTOTUNE\n",
        "  ).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "print( finetune_val_ds.take(1).get_single_element() )\n"
      ],
      "metadata": {
        "id": "K1H7mA_8BmSc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoder_model = keras.models.load_model(\"encoder_model\", compile=False)\n",
        "\n",
        "inputs = keras.Input(shape=(SEQ_LENGTH,), dtype=df.int32)\n",
        "\n",
        "encoded_tokens = encoder_model(inputs)\n",
        "pooled_tokens = keras.layers.GlobalAveragePooling1D()(encoded_tokens)\n",
        "\n",
        "outputs = keras.layers.Dense(1, activation=\"sigmoid\")(pooled_tokens)\n",
        "\n",
        "finetuning_model = keras.Model(inputs, outputs)\n",
        "finetuning_model.compile(\n",
        "    loss=\"binary_crossentropy\",\n",
        "    optimizer=keras.optimizers.Adam(learning_rate=FINETUNING_LEARNING_RATE),\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "finetuning_model.fit(\n",
        "    finetune_ds, validation_data=finetune_val_ds, epochs=FINETUNING_EPOCHS,\n",
        ")\n"
      ],
      "metadata": {
        "id": "b6yA53RNG0Fn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = keras.Input(shape=(), dtype=tf.string)\n",
        "tokens = tokenizer(inputs)\n",
        "outputs = finetuning_model(tokens)\n",
        "final_model = keras.Model(inputs, outputs)\n",
        "final_model.save(\"final_model\")\n",
        "\n",
        "restored_model = keras.model.load_model(\"final_model\", compile=False)\n",
        "inference_data = tf.constant([\"Terrible, no good, trash.\", \"So great: I loved it!\"])\n",
        "print(restored_model(inference_data))"
      ],
      "metadata": {
        "id": "5saN7mAFIfeS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}